{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fGbv5s4vSzf1"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "train.drop(columns=['id'], inplace=True)\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "test.drop(columns=['id'], inplace=True)\n",
    "\n",
    "print(\"Train Details\\n\")\n",
    "print(f\"Train Data Info: {train.info()}\")\n",
    "print(f\"N/A values: {train.isnull().sum()}\")\n",
    "print(f\"Train data description: {train.describe()}\")\n",
    "for column in train.select_dtypes(include=['object']).columns:\n",
    "    unique_values = train[column].unique()\n",
    "    print(f\"\\nUnique values in column '{column}': {unique_values}\")\n",
    "display(train.head())\n",
    "\n",
    "print(\"Test Details\\n\\n\")\n",
    "print(f\"Test Data Info: {test.info()}\")\n",
    "print(f\"N/A Values: {test.isnull().sum()}\")\n",
    "print(f\"Test data description: {test.describe()}\")\n",
    "for column in test.select_dtypes(include=['object']).columns:\n",
    "    unique_values = test[column].unique()\n",
    "    print(f\"\\nUnique values in column '{column}': {unique_values}\")\n",
    "display(test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histograms of raw data\n",
    "for col in train.select_dtypes(include=['float64']).columns:\n",
    "    data = train[col].dropna()\n",
    "\n",
    "    # Descriptive statistics\n",
    "    q1 = data.quantile(0.25)\n",
    "    q3 = data.quantile(0.75)\n",
    "\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    sns.histplot(x=data, kde=True, bins=25)\n",
    "\n",
    "    # Vertical lines\n",
    "    plt.axvline(data.mean(), linestyle='--', linewidth=2, label=f\"Mean: {data.mean():.2f}\")\n",
    "    plt.axvline(data.median(), linestyle='-', linewidth=2, label=f\"Median: {data.median():.2f}\")\n",
    "    plt.axvline(data.min(), linestyle='-', linewidth=2, label=f\"Min: {data.min():.2f}\")\n",
    "    plt.axvline(data.quantile(0.25), linestyle=':', linewidth=2, label=f\"Q1: {data.quantile(0.25):.2f}\")\n",
    "    plt.axvline(data.quantile(0.75), linestyle=':', linewidth=2, label=f\"Q3: {data.quantile(0.75):.2f}\")\n",
    "    plt.axvline(data.max(), linestyle='-', linewidth=2, label=f\"Max: {data.max():.2f}\")\n",
    "    \n",
    "\n",
    "    # Stats text box\n",
    "    stats_text = (\n",
    "        f\"Mean: {data.mean():.2f}\\n\"\n",
    "        f\"Median: {data.median():.2f}\\n\"\n",
    "        f\"Std Dev: {data.std():.2f}\\n\"\n",
    "        f\"Q1: {q1:.2f}\\n\"\n",
    "        f\"Q3: {q3:.2f}\"\n",
    "    )\n",
    "\n",
    "    plt.text(\n",
    "        0.98, 0.95, stats_text,\n",
    "        transform=plt.gca().transAxes,\n",
    "        verticalalignment='top',\n",
    "        horizontalalignment='right',\n",
    "        bbox=dict(boxstyle='round', alpha=0.3)\n",
    "    )\n",
    "\n",
    "    plt.title(f\"Distribution of {col}\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_na(df):\n",
    "    df['Age'].fillna(df['Age'].median(), inplace=True)\n",
    "    df['Annual Income'].fillna(df['Annual Income'].median(), inplace=True)\n",
    "    df['Number of Dependents'].fillna(df['Number of Dependents'].median(), inplace=True)\n",
    "    df['Health Score'].fillna(df['Health Score'].mean(), inplace=True)\n",
    "    df['Previous Claims'].fillna(df['Previous Claims'].median(), inplace=True)\n",
    "    df['Vehicle Age'].fillna(df['Vehicle Age'].median(), inplace=True)\n",
    "    df['Credit Score'].fillna(df['Credit Score'].mean(), inplace=True)\n",
    "    df['Insurance Duration'].fillna(df['Insurance Duration'].median(), inplace=True)\n",
    "    df['Customer Feedback'].fillna(df['Customer Feedback'].mode()[0], inplace=True)\n",
    "    df['Marital Status'].fillna(df['Marital Status'].mode()[0], inplace=True)\n",
    "    df['Occupation'].fillna(df['Occupation'].mode()[0], inplace=True)\n",
    "    return df\n",
    "train = fill_na(train)\n",
    "test = fill_na(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After filling NA values Histograms\n",
    "for col in train.select_dtypes(include=['float64']).columns:\n",
    "    data = train[col].dropna()\n",
    "\n",
    "    # Descriptive statistics\n",
    "    q1 = data.quantile(0.25)\n",
    "    q3 = data.quantile(0.75)\n",
    "\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    sns.histplot(x=data, kde=True, bins=25)\n",
    "\n",
    "    # Vertical lines\n",
    "    plt.axvline(data.mean(), linestyle='--', linewidth=2, label=f\"Mean: {data.mean():.2f}\")\n",
    "    plt.axvline(data.median(), linestyle='-', linewidth=2, label=f\"Median: {data.median():.2f}\")\n",
    "    plt.axvline(data.min(), linestyle='-', linewidth=2, label=f\"Min: {data.min():.2f}\")\n",
    "    plt.axvline(data.quantile(0.25), linestyle=':', linewidth=2, label=f\"Q1: {data.quantile(0.25):.2f}\")\n",
    "    plt.axvline(data.quantile(0.75), linestyle=':', linewidth=2, label=f\"Q3: {data.quantile(0.75):.2f}\")\n",
    "    plt.axvline(data.max(), linestyle='-', linewidth=2, label=f\"Max: {data.max():.2f}\")\n",
    "    \n",
    "    # Stats text box\n",
    "    stats_text = (\n",
    "        f\"Mean: {data.mean():.2f}\\n\"\n",
    "        f\"Median: {data.median():.2f}\\n\"\n",
    "        f\"Std Dev: {data.std():.2f}\\n\"\n",
    "        f\"Q1: {q1:.2f}\\n\"\n",
    "        f\"Q3: {q3:.2f}\"\n",
    "    )\n",
    "\n",
    "    plt.text(\n",
    "        0.98, 0.95, stats_text,\n",
    "        transform=plt.gca().transAxes,\n",
    "        verticalalignment='top',\n",
    "        horizontalalignment='right',\n",
    "        bbox=dict(boxstyle='round', alpha=0.3)\n",
    "    )\n",
    "\n",
    "    plt.title(f\"Distribution of {col}\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_encode(df):\n",
    "    df['Gender'] = df['Gender'].map({'Male': 0, 'Female': 1})\n",
    "    df['Smoking Status'] = df['Smoking Status'].map({'No': 0, 'Yes': 1})\n",
    "    return df\n",
    "train = binary_encode(train)\n",
    "test = binary_encode(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(df):\n",
    "    df['Policy Start Date'] = pd.to_datetime(df['Policy Start Date'], errors='coerce')\n",
    "    df['year'] = df['Policy Start Date'].dt.year\n",
    "    df['month'] = df['Policy Start Date'].dt.month\n",
    "    df['day'] = df['Policy Start Date'].dt.day\n",
    "    df['dow'] = df['Policy Start Date'].dt.dayofweek\n",
    "    df['is_weekend'] = (df['dow'] >= 5).astype(int)\n",
    "    \n",
    "    df['log_income'] = np.log1p(df['Annual Income'])\n",
    "    df['income_per_age'] = df['Annual Income'] / (df['Age'] + 1)\n",
    "    df['income_per_dependent'] = df['Annual Income'] / (df['Number of Dependents'] + 1)\n",
    "    df['high_income'] = (df['Annual Income'] > 100000).astype(int)\n",
    "    \n",
    "    df['age_group'] = pd.cut(df['Age'], bins=[0, 30, 41, 53, 100], labels=[0,1,2,3]).astype(int)\n",
    "    df['age_times_log_income'] = df['Age'] * df['log_income']\n",
    "    df['age_times_dependents'] = df['Age'] * df['Number of Dependents']\n",
    "    \n",
    "    df['smoker'] = (df['Smoking Status'] == '1').astype(int)\n",
    "    df['sedentary'] = (df['Exercise Frequency'] == 'Rarely').astype(int)\n",
    "    df['risk_score'] = df['smoker']*3 + df['sedentary']*2 + (df['Health Score'] < 20).astype(int)*2\n",
    "    \n",
    "    df['creditworthiness'] = pd.qcut(df['Credit Score'], q=10, labels=False, duplicates='drop')\n",
    "    df['new_car'] = (df['Vehicle Age'] <= 3).astype(int)\n",
    "    df['long_duration'] = (df['Insurance Duration'] >= 5).astype(int)\n",
    "    df['many_claims'] = (df['Previous Claims'] >= 3).astype(int)\n",
    "    df['top_policy'] = (df['Policy Type'] == 'Premium').astype(int)\n",
    "    \n",
    "    df['log_income_times_risk'] = df['log_income'] * df['risk_score']\n",
    "    df['age_times_risk'] = df['Age'] * df['risk_score']\n",
    "    df['credit_times_log_income'] = df['Credit Score'] * df['log_income']\n",
    "    df['health_times_log_income'] = df['Health Score'] * df['log_income']\n",
    "    \n",
    "    freq_cols = ['Gender','Marital Status','Education Level','Occupation','Location', 'Policy Type','Property Type','Smoking Status','Exercise Frequency']\n",
    "    \n",
    "    for col in freq_cols:\n",
    "        df[f'{col}_freq'] = df[col].map(df[col].value_counts(normalize=True))\n",
    "    \n",
    "    df = df.drop(columns=['Policy Start Date','Customer Feedback'], errors='ignore')\n",
    "    return df\n",
    "\n",
    "train=create_features(train)\n",
    "test=create_features(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(train.head(10))\n",
    "display(train.info())\n",
    "display(test.head(10))\n",
    "display(test.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder, LabelEncoder\n",
    "# Ordinal Encoding\n",
    "ordinal_cols = ['Education Level', 'Exercise Frequency', 'Policy Type']\n",
    "tiers = [['High School', \"Bachelor's\", \"Master's\", 'PhD'], ['Rarely', 'Monthly', 'Weekly', 'Daily'], ['Basic', 'Comprehensive', 'Premium']]\n",
    "order = OrdinalEncoder(categories=tiers)\n",
    "train[ordinal_cols] = order.fit_transform(train[ordinal_cols])\n",
    "test[ordinal_cols] = order.transform(test[ordinal_cols])\n",
    "\n",
    "# Nominal Encoding\n",
    "nominal_cols = ['Marital Status', 'Occupation', 'Location', 'Property Type']\n",
    "nominal_encoders = {}\n",
    "for col in nominal_cols:\n",
    "    le = LabelEncoder()\n",
    "    train[col] = le.fit_transform(train[col])\n",
    "    nominal_encoders[col] = le\n",
    "    test[col] = le.transform(test[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert isinstance(train, pd.DataFrame), \"train must be a pandas DataFrame\"\n",
    "assert isinstance(test,  pd.DataFrame), \"test must be a pandas DataFrame\"\n",
    "assert 'Premium Amount' in train.columns, \"Target column 'Premium Amount' not found in train\"\n",
    "\n",
    "y = train['Premium Amount'].copy()              \n",
    "X = train.drop(columns=['Premium Amount'])      \n",
    "\n",
    "assert X.shape[0] == y.shape[0]\n",
    "\n",
    "n_train = X.shape[0]\n",
    "n_test  = test.shape[0]\n",
    "\n",
    "oof_pred  = np.zeros(n_train, dtype=np.float64)\n",
    "test_pred = np.zeros(n_test,  dtype=np.float64)\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "print(\"5-fold CV with Histogram Gradient Boosting\\n\")\n",
    "start_total = time.time()\n",
    "\n",
    "for fold, (ti, vi) in enumerate(kf.split(X)):\n",
    "    fold_start = time.time()\n",
    "    print(f\"Fold {fold+1}/5 training... \", end=\"\", flush=True)\n",
    "\n",
    "    X_tr, X_va = X.iloc[ti], X.iloc[vi]\n",
    "    y_tr = np.log1p(y.iloc[ti])\n",
    "\n",
    "    model = HistGradientBoostingRegressor(\n",
    "        loss=\"squared_error\",\n",
    "        learning_rate=0.05,\n",
    "        max_depth=7,\n",
    "        max_iter=800,\n",
    "        max_leaf_nodes=31,\n",
    "        l2_regularization=2.0,\n",
    "        early_stopping=True,\n",
    "        validation_fraction=0.1,\n",
    "        n_iter_no_change=50,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    model.fit(X_tr, y_tr)\n",
    "\n",
    "    oof_pred[vi] = np.expm1(model.predict(X_va))\n",
    "\n",
    "    test_pred += np.expm1(model.predict(test)) / kf.n_splits\n",
    "\n",
    "    rmsle = mean_squared_log_error(y.iloc[vi], oof_pred[vi]) ** 0.5\n",
    "    fold_time = time.time() - fold_start\n",
    "    folds_left = kf.n_splits - fold - 1\n",
    "    est_remaining = folds_left * fold_time\n",
    "\n",
    "    print(\n",
    "        f\"Done | RMSLE: {rmsle:.6f} | \"\n",
    "        f\"Time: {fold_time/60:.1f}min | \"\n",
    "        f\"{folds_left} left â‰ˆ {est_remaining/60:.1f}min\"\n",
    "    )\n",
    "\n",
    "total_time = time.time() - start_total\n",
    "cv_score = mean_squared_log_error(y, oof_pred) ** 0.5\n",
    "\n",
    "print(f\"\\nAll 5 folds done in {total_time/60:.1f} minutes\")\n",
    "print(f\"FINAL 5-fold CV RMSLE: {cv_score:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv('sample_submission.csv')\n",
    "sub['Premium Amount'] = test_pred\n",
    "sub.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "SpvkTQAdPlM-",
    "dXjrZ-tDkPSz",
    "te0d1ppWPlNP",
    "Rh_gGhLTPlNR",
    "yWk68nx1PlNO",
    "Pef3ACclBPxo",
    "sEzuGmA7PlNS",
    "jDEIrhxJb49S",
    "DqyCkdeCPlNV"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
